Project Description:-

A) Organisation Name: Walmart

B) Country: United States of America

C) Programming Langauge: Python

D) Kaggle Data Source : https://www.kaggle.com/datasets/mikhail1681/walmart-sales

E) Algorithms Applied:

     1) Linear Regression

     2) Random Forest Regressor

F) Time Period (Year): 2010-2012

G) Objective:-
   - The project focuses on building a machine learing model that focuses on forecasting the weekly sales of Walmart based on historical data with the help of supervised 
     learning algorithms.
  
   - It also explains the impact of independent variables on the weekly sales of all the stores across the US and how much do they account for the variability in the sales.

H) Model process:
    The model follows 5 major steps, which are:-

     1) Data Acquisition: The database concerning Walmart's sales has been acquired from Kaggle and been uploaded for further analysis.
     
     2) Data Cleaning: Certain inaccuracies have been eradicated from the databases in order to make the prediction model more robust.
     
     3) Training and testing of dataset: 70% of the dataset has been allocated for it's training through Linear regression model and 30% of the testing of the model.
     
     4) Model Testing: After the linear Regression Model was tested based on 3 crucial metrics ( Cofficient of Determination, Mean Absolute Error & Mean Squared Error), the 
        model was concluded to be unfit for the sales prediction process. Due to which, a more robust algorithm named Random Forest Regressor has been employed in order to 
        make the model more accurate. Based on which, the testing and training procedure was repeated.

     5) Model Deployment: After there was an improvement in Cofficient of Determination, Mean Absolute Error and Mean Squared Error. It can be concluded that the Random 
        Forest Regressor model can be deployed in order to progress with sales prediction process. 

I) Impact:

     1) Increasing Cofficient of determination by 14%.
     
     2) Decreasing Mean Squared Error by 14%.

     3) Decreasing Mean Absolute Error by 21%.
     
     
